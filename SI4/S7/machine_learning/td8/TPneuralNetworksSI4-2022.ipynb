{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP réseaux de neurones\n",
    "\n",
    "Diane Lingrand (diane.lingrand@univ-cotedazur.fr)\n",
    "\n",
    "Polytech SI4 - CVML - 2022-23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports nécessaires pour la suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T13:51:34.286491Z",
     "start_time": "2022-11-14T13:51:27.172676Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation \n",
    "import tensorflow.keras.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T13:52:05.755716Z",
     "start_time": "2022-11-14T13:52:05.420903Z"
    }
   },
   "outputs": [],
   "source": [
    "# reading the dataset\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T13:58:46.141357Z",
     "start_time": "2022-11-14T13:58:46.136121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train: (60000, 28, 28)\n",
      "shape of y_train: (60000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of x_train:\", x_train.shape)\n",
    "print(\"shape of y_train:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T13:52:06.104027Z",
     "start_time": "2022-11-14T13:52:05.967253Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display a random image from the train dataset (re-run the cell in order to change the image)\n",
    "import matplotlib.pyplot as plt\n",
    "i = random.randint(0,len(x_train)-1)\n",
    "plt.imshow(x_train[i],aspect=\"auto\",cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 1. Un premier MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nbClasses=10\n",
    "# Let's build a simple neural network using the keras sequential method\n",
    "model = Sequential()\n",
    "#topology: input as the size of data, one hidden layer with 4 neurons and usual sigmoid activation\n",
    "topology = [x_train.shape[1], 4, nbClasses]\n",
    "# softmax for the output using as many neurons as classes \n",
    "output_activation = 'softmax'\n",
    "\n",
    "# first hidden layer\n",
    "nbNeuronsHL = 20\n",
    "model.add(Dense(nbNeuronsHL, input_dim=784, activation='sigmoid'))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(nbClasses, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 20)                15700     \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,910\n",
      "Trainable params: 15,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# we need to define the loss function for the training, the optimisation method (RMSprop) and the accuracy as a metric\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 2s 2ms/step - loss: 1.0895 - accuracy: 0.7656\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4532 - accuracy: 0.8924\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3328 - accuracy: 0.9112\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2852 - accuracy: 0.9207\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2574 - accuracy: 0.9276\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2378 - accuracy: 0.9324\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2224 - accuracy: 0.9372\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2098 - accuracy: 0.9406\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1996 - accuracy: 0.9434\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1907 - accuracy: 0.9462\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1832 - accuracy: 0.9481\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1762 - accuracy: 0.9504\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1706 - accuracy: 0.9515\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1651 - accuracy: 0.9526\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1601 - accuracy: 0.9542\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1561 - accuracy: 0.9549\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1519 - accuracy: 0.9567\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1482 - accuracy: 0.9577\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1449 - accuracy: 0.9582\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1419 - accuracy: 0.9592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcc6c7c1d20>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train, nbClasses)\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test, nbClasses)\n",
    "\n",
    "# now, let's train for real the network: only 20 epochs and batch size of 128 (so that an epoch contains 60000/128 iterations)\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Que vaut le score F1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# f1 score\n",
    "y_pred = model.predict(x_test)\n",
    "#f1 = f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## A t-on laissé le temps à l'algorithme de converger?\n",
    "Modifiez le nombre d'itérations. Les résultats sont-ils meilleurs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non. L'algo avait déjà convergé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Critère d'arrêt autre que le nombre d'itérations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In this small example, we decided, as a default behavior, to stop after 20 epochs. Of course this value can be changed. Another way to deal with that is to use early stopping criterion. All options are described in the keras documentation. Feel free to experiment all options!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1412 - accuracy: 0.9596 - val_loss: 0.1301 - val_accuracy: 0.9624\n",
      "Epoch 2/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1381 - accuracy: 0.9604 - val_loss: 0.1308 - val_accuracy: 0.9627\n",
      "Epoch 3/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1355 - accuracy: 0.9617 - val_loss: 0.1304 - val_accuracy: 0.9622\n",
      "Epoch 4/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1328 - accuracy: 0.9620 - val_loss: 0.1316 - val_accuracy: 0.9616\n",
      "Epoch 5/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1306 - accuracy: 0.9627 - val_loss: 0.1305 - val_accuracy: 0.9616\n",
      "Epoch 6/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1283 - accuracy: 0.9628 - val_loss: 0.1325 - val_accuracy: 0.9617\n",
      "Epoch 7/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1264 - accuracy: 0.9636 - val_loss: 0.1320 - val_accuracy: 0.9612\n",
      "Epoch 8/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1246 - accuracy: 0.9643 - val_loss: 0.1316 - val_accuracy: 0.9612\n",
      "Epoch 9/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1228 - accuracy: 0.9651 - val_loss: 0.1319 - val_accuracy: 0.9609\n",
      "Epoch 10/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1210 - accuracy: 0.9653 - val_loss: 0.1318 - val_accuracy: 0.9615\n",
      "Epoch 11/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1193 - accuracy: 0.9661 - val_loss: 0.1318 - val_accuracy: 0.9607\n",
      "Epoch 12/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1178 - accuracy: 0.9666 - val_loss: 0.1325 - val_accuracy: 0.9609\n",
      "Epoch 13/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1160 - accuracy: 0.9663 - val_loss: 0.1328 - val_accuracy: 0.9605\n",
      "Epoch 14/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1144 - accuracy: 0.9676 - val_loss: 0.1320 - val_accuracy: 0.9600\n",
      "Epoch 15/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1131 - accuracy: 0.9680 - val_loss: 0.1326 - val_accuracy: 0.9600\n",
      "Epoch 16/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1117 - accuracy: 0.9685 - val_loss: 0.1320 - val_accuracy: 0.9618\n",
      "Epoch 17/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1104 - accuracy: 0.9685 - val_loss: 0.1310 - val_accuracy: 0.9617\n",
      "Epoch 18/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1090 - accuracy: 0.9686 - val_loss: 0.1324 - val_accuracy: 0.9607\n",
      "Epoch 19/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1077 - accuracy: 0.9691 - val_loss: 0.1315 - val_accuracy: 0.9614\n",
      "Epoch 20/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1068 - accuracy: 0.9696 - val_loss: 0.1323 - val_accuracy: 0.9600\n",
      "Epoch 21/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1054 - accuracy: 0.9705 - val_loss: 0.1336 - val_accuracy: 0.9603\n",
      "Epoch 22/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1044 - accuracy: 0.9701 - val_loss: 0.1339 - val_accuracy: 0.9607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcc6c51c7f0>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# we define a callback function that will control if the accuracy \n",
    "# on the validation set (a part of train set) is not changing more than 10-4 with a patience of 20 iterations\n",
    "# If the last accuracy value is not the best one, we still keep the last results\n",
    "# In this example, we extracted 20% of the train set for the validation set that will be used to monitor the convergence.\n",
    "\n",
    "ourCallback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=20, verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n",
    "\n",
    "# let's learn the network again !\n",
    "# We do not know when the training will stop but no more than 2000 epochs.\n",
    "model.fit(x_train, y_train, epochs=2000, batch_size=128, validation_split=0.2, callbacks=[ourCallback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A quel 'epoch' l'algorithme s'est-il arrêté ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Evolution de la convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "ourCallback = tensorflow.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=20, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T13:59:17.452295Z",
     "start_time": "2022-11-14T13:59:17.303696Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.2186 - accuracy: 0.7377 - val_loss: 0.6782 - val_accuracy: 0.8762\n",
      "Epoch 2/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5421 - accuracy: 0.8821 - val_loss: 0.4097 - val_accuracy: 0.9031\n",
      "Epoch 3/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3833 - accuracy: 0.9029 - val_loss: 0.3267 - val_accuracy: 0.9156\n",
      "Epoch 4/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3220 - accuracy: 0.9136 - val_loss: 0.2889 - val_accuracy: 0.9211\n",
      "Epoch 5/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2881 - accuracy: 0.9210 - val_loss: 0.2648 - val_accuracy: 0.9277\n",
      "Epoch 6/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2650 - accuracy: 0.9261 - val_loss: 0.2490 - val_accuracy: 0.9327\n",
      "Epoch 7/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2479 - accuracy: 0.9313 - val_loss: 0.2373 - val_accuracy: 0.9335\n",
      "Epoch 8/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2341 - accuracy: 0.9351 - val_loss: 0.2263 - val_accuracy: 0.9367\n",
      "Epoch 9/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2223 - accuracy: 0.9381 - val_loss: 0.2187 - val_accuracy: 0.9397\n",
      "Epoch 10/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2124 - accuracy: 0.9409 - val_loss: 0.2117 - val_accuracy: 0.9402\n",
      "Epoch 11/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2037 - accuracy: 0.9432 - val_loss: 0.2049 - val_accuracy: 0.9442\n",
      "Epoch 12/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1960 - accuracy: 0.9459 - val_loss: 0.1998 - val_accuracy: 0.9435\n",
      "Epoch 13/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1894 - accuracy: 0.9470 - val_loss: 0.1954 - val_accuracy: 0.9454\n",
      "Epoch 14/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1833 - accuracy: 0.9488 - val_loss: 0.1915 - val_accuracy: 0.9466\n",
      "Epoch 15/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1775 - accuracy: 0.9508 - val_loss: 0.1884 - val_accuracy: 0.9467\n",
      "Epoch 16/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1725 - accuracy: 0.9518 - val_loss: 0.1845 - val_accuracy: 0.9471\n",
      "Epoch 17/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1678 - accuracy: 0.9536 - val_loss: 0.1815 - val_accuracy: 0.9482\n",
      "Epoch 18/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1642 - accuracy: 0.9545 - val_loss: 0.1788 - val_accuracy: 0.9485\n",
      "Epoch 19/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1601 - accuracy: 0.9554 - val_loss: 0.1770 - val_accuracy: 0.9488\n",
      "Epoch 20/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1566 - accuracy: 0.9562 - val_loss: 0.1749 - val_accuracy: 0.9494\n",
      "Epoch 21/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1531 - accuracy: 0.9566 - val_loss: 0.1736 - val_accuracy: 0.9510\n",
      "Epoch 22/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1500 - accuracy: 0.9573 - val_loss: 0.1717 - val_accuracy: 0.9504\n",
      "Epoch 23/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1474 - accuracy: 0.9586 - val_loss: 0.1704 - val_accuracy: 0.9507\n",
      "Epoch 24/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1445 - accuracy: 0.9591 - val_loss: 0.1698 - val_accuracy: 0.9501\n",
      "Epoch 25/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1418 - accuracy: 0.9597 - val_loss: 0.1683 - val_accuracy: 0.9520\n",
      "Epoch 26/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1398 - accuracy: 0.9604 - val_loss: 0.1671 - val_accuracy: 0.9511\n",
      "Epoch 27/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1373 - accuracy: 0.9607 - val_loss: 0.1666 - val_accuracy: 0.9513\n",
      "Epoch 28/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1353 - accuracy: 0.9621 - val_loss: 0.1648 - val_accuracy: 0.9532\n",
      "Epoch 29/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1331 - accuracy: 0.9625 - val_loss: 0.1643 - val_accuracy: 0.9521\n",
      "Epoch 30/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1311 - accuracy: 0.9629 - val_loss: 0.1651 - val_accuracy: 0.9511\n",
      "Epoch 31/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1293 - accuracy: 0.9631 - val_loss: 0.1618 - val_accuracy: 0.9534\n",
      "Epoch 32/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1275 - accuracy: 0.9643 - val_loss: 0.1624 - val_accuracy: 0.9533\n",
      "Epoch 33/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1259 - accuracy: 0.9647 - val_loss: 0.1609 - val_accuracy: 0.9541\n",
      "Epoch 34/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1238 - accuracy: 0.9650 - val_loss: 0.1604 - val_accuracy: 0.9537\n",
      "Epoch 35/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1227 - accuracy: 0.9654 - val_loss: 0.1602 - val_accuracy: 0.9540\n",
      "Epoch 36/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1207 - accuracy: 0.9661 - val_loss: 0.1593 - val_accuracy: 0.9541\n",
      "Epoch 37/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1197 - accuracy: 0.9662 - val_loss: 0.1598 - val_accuracy: 0.9539\n",
      "Epoch 38/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1180 - accuracy: 0.9665 - val_loss: 0.1582 - val_accuracy: 0.9547\n",
      "Epoch 39/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1168 - accuracy: 0.9672 - val_loss: 0.1580 - val_accuracy: 0.9542\n",
      "Epoch 40/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1154 - accuracy: 0.9672 - val_loss: 0.1579 - val_accuracy: 0.9541\n",
      "Epoch 41/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1141 - accuracy: 0.9683 - val_loss: 0.1588 - val_accuracy: 0.9541\n",
      "Epoch 42/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1130 - accuracy: 0.9677 - val_loss: 0.1585 - val_accuracy: 0.9545\n",
      "Epoch 43/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1117 - accuracy: 0.9683 - val_loss: 0.1581 - val_accuracy: 0.9548\n",
      "Epoch 44/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1103 - accuracy: 0.9687 - val_loss: 0.1570 - val_accuracy: 0.9542\n",
      "Epoch 45/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1095 - accuracy: 0.9688 - val_loss: 0.1571 - val_accuracy: 0.9550\n",
      "Epoch 46/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1083 - accuracy: 0.9692 - val_loss: 0.1563 - val_accuracy: 0.9541\n",
      "Epoch 47/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1073 - accuracy: 0.9691 - val_loss: 0.1584 - val_accuracy: 0.9541\n",
      "Epoch 48/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1062 - accuracy: 0.9701 - val_loss: 0.1571 - val_accuracy: 0.9557\n",
      "Epoch 49/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1051 - accuracy: 0.9705 - val_loss: 0.1574 - val_accuracy: 0.9548\n",
      "Epoch 50/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1043 - accuracy: 0.9707 - val_loss: 0.1575 - val_accuracy: 0.9562\n",
      "Epoch 51/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1031 - accuracy: 0.9708 - val_loss: 0.1557 - val_accuracy: 0.9555\n",
      "Epoch 52/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1022 - accuracy: 0.9708 - val_loss: 0.1567 - val_accuracy: 0.9553\n",
      "Epoch 53/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1011 - accuracy: 0.9711 - val_loss: 0.1564 - val_accuracy: 0.9559\n",
      "Epoch 54/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1004 - accuracy: 0.9716 - val_loss: 0.1572 - val_accuracy: 0.9552\n",
      "Epoch 55/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0995 - accuracy: 0.9717 - val_loss: 0.1569 - val_accuracy: 0.9561\n",
      "Epoch 56/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0986 - accuracy: 0.9722 - val_loss: 0.1564 - val_accuracy: 0.9561\n",
      "Epoch 57/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0977 - accuracy: 0.9724 - val_loss: 0.1590 - val_accuracy: 0.9551\n",
      "Epoch 58/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0971 - accuracy: 0.9720 - val_loss: 0.1567 - val_accuracy: 0.9557\n",
      "Epoch 59/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0961 - accuracy: 0.9728 - val_loss: 0.1564 - val_accuracy: 0.9559\n",
      "Epoch 60/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0955 - accuracy: 0.9731 - val_loss: 0.1565 - val_accuracy: 0.9553\n",
      "Epoch 61/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0946 - accuracy: 0.9734 - val_loss: 0.1577 - val_accuracy: 0.9563\n",
      "Epoch 62/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0938 - accuracy: 0.9733 - val_loss: 0.1574 - val_accuracy: 0.9556\n",
      "Epoch 63/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0930 - accuracy: 0.9739 - val_loss: 0.1568 - val_accuracy: 0.9556\n",
      "Epoch 64/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0918 - accuracy: 0.9742 - val_loss: 0.1574 - val_accuracy: 0.9557\n",
      "Epoch 65/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0916 - accuracy: 0.9745 - val_loss: 0.1567 - val_accuracy: 0.9561\n",
      "Epoch 66/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0910 - accuracy: 0.9745 - val_loss: 0.1585 - val_accuracy: 0.9551\n",
      "Epoch 67/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0905 - accuracy: 0.9750 - val_loss: 0.1578 - val_accuracy: 0.9561\n",
      "Epoch 68/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0895 - accuracy: 0.9750 - val_loss: 0.1581 - val_accuracy: 0.9563\n",
      "Epoch 69/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0887 - accuracy: 0.9755 - val_loss: 0.1584 - val_accuracy: 0.9557\n",
      "Epoch 70/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0882 - accuracy: 0.9749 - val_loss: 0.1582 - val_accuracy: 0.9552\n",
      "Epoch 71/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0876 - accuracy: 0.9757 - val_loss: 0.1587 - val_accuracy: 0.9567\n",
      "Epoch 72/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0871 - accuracy: 0.9760 - val_loss: 0.1594 - val_accuracy: 0.9555\n",
      "Epoch 73/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0863 - accuracy: 0.9758 - val_loss: 0.1583 - val_accuracy: 0.9561\n",
      "Epoch 74/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0857 - accuracy: 0.9762 - val_loss: 0.1602 - val_accuracy: 0.9553\n",
      "Epoch 75/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0853 - accuracy: 0.9761 - val_loss: 0.1583 - val_accuracy: 0.9549\n",
      "Epoch 76/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0844 - accuracy: 0.9762 - val_loss: 0.1607 - val_accuracy: 0.9553\n",
      "Epoch 77/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0838 - accuracy: 0.9765 - val_loss: 0.1603 - val_accuracy: 0.9557\n",
      "Epoch 78/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0833 - accuracy: 0.9768 - val_loss: 0.1596 - val_accuracy: 0.9561\n",
      "Epoch 79/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0827 - accuracy: 0.9771 - val_loss: 0.1593 - val_accuracy: 0.9562\n",
      "Epoch 80/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0822 - accuracy: 0.9774 - val_loss: 0.1593 - val_accuracy: 0.9557\n",
      "Epoch 81/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0815 - accuracy: 0.9776 - val_loss: 0.1600 - val_accuracy: 0.9563\n",
      "Epoch 82/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0812 - accuracy: 0.9773 - val_loss: 0.1600 - val_accuracy: 0.9560\n",
      "Epoch 83/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0806 - accuracy: 0.9775 - val_loss: 0.1609 - val_accuracy: 0.9542\n",
      "Epoch 84/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0802 - accuracy: 0.9782 - val_loss: 0.1595 - val_accuracy: 0.9558\n",
      "Epoch 85/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0795 - accuracy: 0.9780 - val_loss: 0.1614 - val_accuracy: 0.9553\n",
      "Epoch 86/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0790 - accuracy: 0.9783 - val_loss: 0.1613 - val_accuracy: 0.9557\n",
      "Epoch 87/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0787 - accuracy: 0.9783 - val_loss: 0.1616 - val_accuracy: 0.9541\n",
      "Epoch 88/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0781 - accuracy: 0.9784 - val_loss: 0.1626 - val_accuracy: 0.9556\n",
      "Epoch 89/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0776 - accuracy: 0.9786 - val_loss: 0.1617 - val_accuracy: 0.9557\n",
      "Epoch 90/2000\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0770 - accuracy: 0.9791 - val_loss: 0.1608 - val_accuracy: 0.9559\n",
      "Epoch 91/2000\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0767 - accuracy: 0.9787 - val_loss: 0.1634 - val_accuracy: 0.9545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=2000, batch_size=128, validation_split=0.2, callbacks=[ourCallback])\n",
    "DataFrame(history.history).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 3. Changements de topologie\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Est-ce qu'augmenter le nombre de neurones par couche augmente les performances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.9338 - accuracy: 0.7944 - val_loss: 0.4353 - val_accuracy: 0.8974\n",
      "Epoch 2/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3798 - accuracy: 0.9013 - val_loss: 0.3078 - val_accuracy: 0.9176\n",
      "Epoch 3/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2995 - accuracy: 0.9166 - val_loss: 0.2636 - val_accuracy: 0.9269\n",
      "Epoch 4/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2613 - accuracy: 0.9259 - val_loss: 0.2379 - val_accuracy: 0.9338\n",
      "Epoch 5/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2354 - accuracy: 0.9326 - val_loss: 0.2210 - val_accuracy: 0.9364\n",
      "Epoch 6/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2154 - accuracy: 0.9385 - val_loss: 0.2077 - val_accuracy: 0.9408\n",
      "Epoch 7/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1993 - accuracy: 0.9434 - val_loss: 0.1963 - val_accuracy: 0.9450\n",
      "Epoch 8/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1855 - accuracy: 0.9472 - val_loss: 0.1852 - val_accuracy: 0.9485\n",
      "Epoch 9/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1733 - accuracy: 0.9507 - val_loss: 0.1766 - val_accuracy: 0.9511\n",
      "Epoch 10/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1630 - accuracy: 0.9537 - val_loss: 0.1702 - val_accuracy: 0.9535\n",
      "Epoch 11/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1539 - accuracy: 0.9561 - val_loss: 0.1642 - val_accuracy: 0.9541\n",
      "Epoch 12/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1459 - accuracy: 0.9585 - val_loss: 0.1601 - val_accuracy: 0.9556\n",
      "Epoch 13/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1390 - accuracy: 0.9606 - val_loss: 0.1546 - val_accuracy: 0.9561\n",
      "Epoch 14/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1323 - accuracy: 0.9625 - val_loss: 0.1499 - val_accuracy: 0.9572\n",
      "Epoch 15/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1264 - accuracy: 0.9642 - val_loss: 0.1464 - val_accuracy: 0.9579\n",
      "Epoch 16/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1209 - accuracy: 0.9660 - val_loss: 0.1446 - val_accuracy: 0.9598\n",
      "Epoch 17/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1163 - accuracy: 0.9669 - val_loss: 0.1405 - val_accuracy: 0.9598\n",
      "Epoch 18/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1117 - accuracy: 0.9686 - val_loss: 0.1378 - val_accuracy: 0.9603\n",
      "Epoch 19/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1074 - accuracy: 0.9697 - val_loss: 0.1360 - val_accuracy: 0.9604\n",
      "Epoch 20/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1036 - accuracy: 0.9710 - val_loss: 0.1350 - val_accuracy: 0.9613\n",
      "Epoch 21/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0999 - accuracy: 0.9722 - val_loss: 0.1321 - val_accuracy: 0.9615\n",
      "Epoch 22/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0966 - accuracy: 0.9734 - val_loss: 0.1293 - val_accuracy: 0.9617\n",
      "Epoch 23/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0933 - accuracy: 0.9740 - val_loss: 0.1287 - val_accuracy: 0.9628\n",
      "Epoch 24/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0904 - accuracy: 0.9746 - val_loss: 0.1270 - val_accuracy: 0.9614\n",
      "Epoch 25/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0875 - accuracy: 0.9753 - val_loss: 0.1262 - val_accuracy: 0.9621\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1227 - accuracy: 0.9625\n",
      "Test score: 0.12272613495588303\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(nbNeuronsHL * 2, input_dim=784, activation='sigmoid'))\n",
    "model.add(Dense(nbClasses, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=25, batch_size=128, validation_split=0.2)\n",
    "print(\"Test score:\", model.evaluate(x_test, y_test)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Est-ce qu'augmenter le nombre de couches de neurones augmente les performances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.7340 - accuracy: 0.6306 - val_loss: 1.1824 - val_accuracy: 0.7987\n",
      "Epoch 2/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8753 - accuracy: 0.8350 - val_loss: 0.6243 - val_accuracy: 0.8735\n",
      "Epoch 3/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5254 - accuracy: 0.8805 - val_loss: 0.4182 - val_accuracy: 0.8986\n",
      "Epoch 4/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3897 - accuracy: 0.9001 - val_loss: 0.3388 - val_accuracy: 0.9101\n",
      "Epoch 5/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3276 - accuracy: 0.9124 - val_loss: 0.2971 - val_accuracy: 0.9188\n",
      "Epoch 6/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2910 - accuracy: 0.9209 - val_loss: 0.2722 - val_accuracy: 0.9243\n",
      "Epoch 7/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2655 - accuracy: 0.9267 - val_loss: 0.2525 - val_accuracy: 0.9291\n",
      "Epoch 8/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2458 - accuracy: 0.9316 - val_loss: 0.2370 - val_accuracy: 0.9331\n",
      "Epoch 9/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2298 - accuracy: 0.9357 - val_loss: 0.2265 - val_accuracy: 0.9352\n",
      "Epoch 10/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2168 - accuracy: 0.9386 - val_loss: 0.2166 - val_accuracy: 0.9379\n",
      "Epoch 11/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2052 - accuracy: 0.9423 - val_loss: 0.2079 - val_accuracy: 0.9403\n",
      "Epoch 12/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1951 - accuracy: 0.9445 - val_loss: 0.2015 - val_accuracy: 0.9424\n",
      "Epoch 13/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1868 - accuracy: 0.9472 - val_loss: 0.1953 - val_accuracy: 0.9447\n",
      "Epoch 14/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1793 - accuracy: 0.9491 - val_loss: 0.1901 - val_accuracy: 0.9461\n",
      "Epoch 15/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1723 - accuracy: 0.9510 - val_loss: 0.1858 - val_accuracy: 0.9481\n",
      "Epoch 16/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1664 - accuracy: 0.9523 - val_loss: 0.1826 - val_accuracy: 0.9484\n",
      "Epoch 17/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1610 - accuracy: 0.9536 - val_loss: 0.1785 - val_accuracy: 0.9492\n",
      "Epoch 18/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1556 - accuracy: 0.9557 - val_loss: 0.1775 - val_accuracy: 0.9498\n",
      "Epoch 19/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1511 - accuracy: 0.9563 - val_loss: 0.1743 - val_accuracy: 0.9517\n",
      "Epoch 20/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1469 - accuracy: 0.9578 - val_loss: 0.1701 - val_accuracy: 0.9529\n",
      "Epoch 21/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1429 - accuracy: 0.9589 - val_loss: 0.1713 - val_accuracy: 0.9519\n",
      "Epoch 22/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1390 - accuracy: 0.9598 - val_loss: 0.1688 - val_accuracy: 0.9540\n",
      "Epoch 23/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1357 - accuracy: 0.9610 - val_loss: 0.1638 - val_accuracy: 0.9546\n",
      "Epoch 24/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1321 - accuracy: 0.9619 - val_loss: 0.1620 - val_accuracy: 0.9547\n",
      "Epoch 25/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1290 - accuracy: 0.9628 - val_loss: 0.1616 - val_accuracy: 0.9550\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1621 - accuracy: 0.9546\n",
      "Test score: 0.1621023714542389\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(nbNeuronsHL, input_dim=784, activation='sigmoid'))\n",
    "model.add(Dense(nbNeuronsHL, activation='sigmoid'))\n",
    "model.add(Dense(nbClasses, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=25, batch_size=128, validation_split=0.2)\n",
    "print(\"Test score:\", model.evaluate(x_test, y_test)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Si vous observez qu'en augmentant le nombre de couches cachées, les performances chutent, essayez de remplacer l'activiation 'sigmoid' par 'relu'. Est-ce mieux ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.6663 - accuracy: 0.8129 - val_loss: 0.3160 - val_accuracy: 0.9122\n",
      "Epoch 2/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2876 - accuracy: 0.9183 - val_loss: 0.2563 - val_accuracy: 0.9261\n",
      "Epoch 3/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2373 - accuracy: 0.9327 - val_loss: 0.2106 - val_accuracy: 0.9408\n",
      "Epoch 4/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2095 - accuracy: 0.9404 - val_loss: 0.1960 - val_accuracy: 0.9456\n",
      "Epoch 5/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1915 - accuracy: 0.9454 - val_loss: 0.1826 - val_accuracy: 0.9495\n",
      "Epoch 6/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1760 - accuracy: 0.9500 - val_loss: 0.1728 - val_accuracy: 0.9513\n",
      "Epoch 7/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1643 - accuracy: 0.9525 - val_loss: 0.1671 - val_accuracy: 0.9517\n",
      "Epoch 8/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1547 - accuracy: 0.9550 - val_loss: 0.1583 - val_accuracy: 0.9548\n",
      "Epoch 9/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1462 - accuracy: 0.9577 - val_loss: 0.1588 - val_accuracy: 0.9546\n",
      "Epoch 10/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1393 - accuracy: 0.9599 - val_loss: 0.1561 - val_accuracy: 0.9571\n",
      "Epoch 11/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1328 - accuracy: 0.9617 - val_loss: 0.1558 - val_accuracy: 0.9547\n",
      "Epoch 12/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1272 - accuracy: 0.9634 - val_loss: 0.1594 - val_accuracy: 0.9549\n",
      "Epoch 13/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1218 - accuracy: 0.9651 - val_loss: 0.1566 - val_accuracy: 0.9556\n",
      "Epoch 14/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1171 - accuracy: 0.9664 - val_loss: 0.1532 - val_accuracy: 0.9578\n",
      "Epoch 15/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1124 - accuracy: 0.9673 - val_loss: 0.1465 - val_accuracy: 0.9588\n",
      "Epoch 16/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1091 - accuracy: 0.9674 - val_loss: 0.1487 - val_accuracy: 0.9582\n",
      "Epoch 17/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1056 - accuracy: 0.9694 - val_loss: 0.1442 - val_accuracy: 0.9596\n",
      "Epoch 18/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1026 - accuracy: 0.9701 - val_loss: 0.1454 - val_accuracy: 0.9617\n",
      "Epoch 19/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0993 - accuracy: 0.9706 - val_loss: 0.1477 - val_accuracy: 0.9585\n",
      "Epoch 20/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0964 - accuracy: 0.9718 - val_loss: 0.1436 - val_accuracy: 0.9613\n",
      "Epoch 21/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0939 - accuracy: 0.9728 - val_loss: 0.1507 - val_accuracy: 0.9596\n",
      "Epoch 22/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0913 - accuracy: 0.9735 - val_loss: 0.1407 - val_accuracy: 0.9620\n",
      "Epoch 23/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0888 - accuracy: 0.9748 - val_loss: 0.1547 - val_accuracy: 0.9595\n",
      "Epoch 24/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0866 - accuracy: 0.9748 - val_loss: 0.1456 - val_accuracy: 0.9630\n",
      "Epoch 25/25\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0848 - accuracy: 0.9755 - val_loss: 0.1438 - val_accuracy: 0.9619\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1436 - accuracy: 0.9611\n",
      "Test score: 0.14361977577209473\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(nbNeuronsHL, input_dim=784, activation='relu'))\n",
    "model.add(Dense(nbNeuronsHL, activation='relu'))\n",
    "model.add(Dense(nbClasses, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=25, batch_size=128, validation_split=0.2)\n",
    "print(\"Test score:\", model.evaluate(x_test, y_test)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 4. Modifiez les données en considérant FMNIST (Fashion MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train: (60000, 28, 28)\n",
      "shape of y_train: (60000,)\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5848 - accuracy: 0.7946 - val_loss: 0.4564 - val_accuracy: 0.8338\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4074 - accuracy: 0.8517 - val_loss: 0.3840 - val_accuracy: 0.8587\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3598 - accuracy: 0.8668 - val_loss: 0.3625 - val_accuracy: 0.8669\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3269 - accuracy: 0.8800 - val_loss: 0.3402 - val_accuracy: 0.8791\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3081 - accuracy: 0.8863 - val_loss: 0.3252 - val_accuracy: 0.8852\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2916 - accuracy: 0.8909 - val_loss: 0.3116 - val_accuracy: 0.8862\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2742 - accuracy: 0.8976 - val_loss: 0.3302 - val_accuracy: 0.8830\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2618 - accuracy: 0.9034 - val_loss: 0.3346 - val_accuracy: 0.8812\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2529 - accuracy: 0.9068 - val_loss: 0.3263 - val_accuracy: 0.8851\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2416 - accuracy: 0.9100 - val_loss: 0.3211 - val_accuracy: 0.8892\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2333 - accuracy: 0.9128 - val_loss: 0.3090 - val_accuracy: 0.8947\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2239 - accuracy: 0.9158 - val_loss: 0.3240 - val_accuracy: 0.8892\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2167 - accuracy: 0.9199 - val_loss: 0.3221 - val_accuracy: 0.8903\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2103 - accuracy: 0.9213 - val_loss: 0.3072 - val_accuracy: 0.8907\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2024 - accuracy: 0.9256 - val_loss: 0.3178 - val_accuracy: 0.8909\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1962 - accuracy: 0.9266 - val_loss: 0.3134 - val_accuracy: 0.8963\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1901 - accuracy: 0.9289 - val_loss: 0.3317 - val_accuracy: 0.8903\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1833 - accuracy: 0.9322 - val_loss: 0.3315 - val_accuracy: 0.8888\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1773 - accuracy: 0.9350 - val_loss: 0.3436 - val_accuracy: 0.8883\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1749 - accuracy: 0.9351 - val_loss: 0.3411 - val_accuracy: 0.8925\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1691 - accuracy: 0.9369 - val_loss: 0.3375 - val_accuracy: 0.8947\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1638 - accuracy: 0.9385 - val_loss: 0.3570 - val_accuracy: 0.8928\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1584 - accuracy: 0.9414 - val_loss: 0.3626 - val_accuracy: 0.8914\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1541 - accuracy: 0.9443 - val_loss: 0.3466 - val_accuracy: 0.8923\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1501 - accuracy: 0.9452 - val_loss: 0.3418 - val_accuracy: 0.8947\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1474 - accuracy: 0.9455 - val_loss: 0.3727 - val_accuracy: 0.8885\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1432 - accuracy: 0.9475 - val_loss: 0.3582 - val_accuracy: 0.8950\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1398 - accuracy: 0.9485 - val_loss: 0.3634 - val_accuracy: 0.8942\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1353 - accuracy: 0.9498 - val_loss: 0.3751 - val_accuracy: 0.8926\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1339 - accuracy: 0.9511 - val_loss: 0.3869 - val_accuracy: 0.8907\n",
      "Epoch 31/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1294 - accuracy: 0.9525 - val_loss: 0.3711 - val_accuracy: 0.8982\n",
      "Epoch 32/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1256 - accuracy: 0.9534 - val_loss: 0.3958 - val_accuracy: 0.8894\n",
      "Epoch 33/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1225 - accuracy: 0.9544 - val_loss: 0.4133 - val_accuracy: 0.8830\n",
      "Epoch 34/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1189 - accuracy: 0.9565 - val_loss: 0.3955 - val_accuracy: 0.8924\n",
      "Epoch 35/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1170 - accuracy: 0.9571 - val_loss: 0.4068 - val_accuracy: 0.8939\n",
      "Epoch 36/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1143 - accuracy: 0.9582 - val_loss: 0.4344 - val_accuracy: 0.8884\n",
      "Epoch 37/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1120 - accuracy: 0.9596 - val_loss: 0.4540 - val_accuracy: 0.8892\n",
      "Epoch 38/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1119 - accuracy: 0.9589 - val_loss: 0.4148 - val_accuracy: 0.8933\n",
      "Epoch 39/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1067 - accuracy: 0.9611 - val_loss: 0.4134 - val_accuracy: 0.8965\n",
      "Epoch 40/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1056 - accuracy: 0.9618 - val_loss: 0.4462 - val_accuracy: 0.8869\n",
      "Epoch 41/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1024 - accuracy: 0.9625 - val_loss: 0.4499 - val_accuracy: 0.8892\n",
      "Epoch 42/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0987 - accuracy: 0.9647 - val_loss: 0.4253 - val_accuracy: 0.8936\n",
      "Epoch 43/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0968 - accuracy: 0.9638 - val_loss: 0.4955 - val_accuracy: 0.8838\n",
      "Epoch 44/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0946 - accuracy: 0.9657 - val_loss: 0.4706 - val_accuracy: 0.8885\n",
      "Epoch 45/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0936 - accuracy: 0.9661 - val_loss: 0.4755 - val_accuracy: 0.8905\n",
      "Epoch 46/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0908 - accuracy: 0.9674 - val_loss: 0.4472 - val_accuracy: 0.8908\n",
      "Epoch 47/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0892 - accuracy: 0.9673 - val_loss: 0.4757 - val_accuracy: 0.8904\n",
      "Epoch 48/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0883 - accuracy: 0.9678 - val_loss: 0.4768 - val_accuracy: 0.8928\n",
      "Epoch 49/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0851 - accuracy: 0.9679 - val_loss: 0.5095 - val_accuracy: 0.8904\n",
      "Epoch 50/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0847 - accuracy: 0.9694 - val_loss: 0.4705 - val_accuracy: 0.8940\n",
      "Epoch 51/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0844 - accuracy: 0.9699 - val_loss: 0.4828 - val_accuracy: 0.8927\n",
      "Epoch 52/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0818 - accuracy: 0.9702 - val_loss: 0.5196 - val_accuracy: 0.8845\n",
      "Epoch 53/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0781 - accuracy: 0.9718 - val_loss: 0.5104 - val_accuracy: 0.8882\n",
      "Epoch 54/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0780 - accuracy: 0.9716 - val_loss: 0.5063 - val_accuracy: 0.8898\n",
      "Epoch 55/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0777 - accuracy: 0.9716 - val_loss: 0.5009 - val_accuracy: 0.8918\n",
      "Epoch 56/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0745 - accuracy: 0.9741 - val_loss: 0.5459 - val_accuracy: 0.8929\n",
      "Epoch 57/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0740 - accuracy: 0.9731 - val_loss: 0.5352 - val_accuracy: 0.8892\n",
      "Epoch 58/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0724 - accuracy: 0.9742 - val_loss: 0.5222 - val_accuracy: 0.8916\n",
      "Epoch 59/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0708 - accuracy: 0.9749 - val_loss: 0.5327 - val_accuracy: 0.8910\n",
      "Epoch 60/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0716 - accuracy: 0.9741 - val_loss: 0.5300 - val_accuracy: 0.8955\n",
      "Epoch 61/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0693 - accuracy: 0.9747 - val_loss: 0.5623 - val_accuracy: 0.8913\n",
      "Epoch 62/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0693 - accuracy: 0.9760 - val_loss: 0.5322 - val_accuracy: 0.8948\n",
      "Epoch 63/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0682 - accuracy: 0.9756 - val_loss: 0.5354 - val_accuracy: 0.8923\n",
      "Epoch 64/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0679 - accuracy: 0.9763 - val_loss: 0.6053 - val_accuracy: 0.8917\n",
      "Epoch 65/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0636 - accuracy: 0.9771 - val_loss: 0.5755 - val_accuracy: 0.8915\n",
      "Epoch 66/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0667 - accuracy: 0.9769 - val_loss: 0.5611 - val_accuracy: 0.8963\n",
      "Epoch 67/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0623 - accuracy: 0.9780 - val_loss: 0.5660 - val_accuracy: 0.8932\n",
      "Epoch 68/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0599 - accuracy: 0.9789 - val_loss: 0.5783 - val_accuracy: 0.8938\n",
      "Epoch 69/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0589 - accuracy: 0.9791 - val_loss: 0.5809 - val_accuracy: 0.8923\n",
      "Epoch 70/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0580 - accuracy: 0.9794 - val_loss: 0.6102 - val_accuracy: 0.8937\n",
      "Epoch 71/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0603 - accuracy: 0.9790 - val_loss: 0.5936 - val_accuracy: 0.8943\n",
      "Epoch 72/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0580 - accuracy: 0.9795 - val_loss: 0.5731 - val_accuracy: 0.8938\n",
      "Epoch 73/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0572 - accuracy: 0.9805 - val_loss: 0.5899 - val_accuracy: 0.8967\n",
      "Epoch 74/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0589 - accuracy: 0.9790 - val_loss: 0.6711 - val_accuracy: 0.8856\n",
      "Epoch 75/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0564 - accuracy: 0.9808 - val_loss: 0.6479 - val_accuracy: 0.8932\n",
      "Epoch 76/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0565 - accuracy: 0.9801 - val_loss: 0.6076 - val_accuracy: 0.8926\n",
      "Epoch 77/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0522 - accuracy: 0.9819 - val_loss: 0.6414 - val_accuracy: 0.8897\n",
      "Epoch 78/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0555 - accuracy: 0.9804 - val_loss: 0.6125 - val_accuracy: 0.8975\n",
      "Epoch 79/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0491 - accuracy: 0.9827 - val_loss: 0.6451 - val_accuracy: 0.8970\n",
      "Epoch 80/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0523 - accuracy: 0.9820 - val_loss: 0.6149 - val_accuracy: 0.8940\n",
      "Epoch 81/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0526 - accuracy: 0.9817 - val_loss: 0.6288 - val_accuracy: 0.8955\n",
      "Epoch 82/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0511 - accuracy: 0.9818 - val_loss: 0.6178 - val_accuracy: 0.8973\n",
      "Epoch 83/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0507 - accuracy: 0.9825 - val_loss: 0.6299 - val_accuracy: 0.8944\n",
      "Epoch 84/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0470 - accuracy: 0.9841 - val_loss: 0.7273 - val_accuracy: 0.8909\n",
      "Epoch 85/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0494 - accuracy: 0.9831 - val_loss: 0.6440 - val_accuracy: 0.8951\n",
      "Epoch 86/100\n",
      "100/375 [=======>......................] - ETA: 0s - loss: 0.0471 - accuracy: 0.9832"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[159], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m y_train \u001b[39m=\u001b[39m tensorflow\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mto_categorical(y_train, nbClasses)\n\u001b[1;32m     25\u001b[0m y_test \u001b[39m=\u001b[39m tensorflow\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mto_categorical(y_test, nbClasses)\n\u001b[0;32m---> 27\u001b[0m model\u001b[39m.\u001b[39;49mfit(x_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n\u001b[1;32m     29\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTest score:\u001b[39m\u001b[39m\"\u001b[39m, model\u001b[39m.\u001b[39mevaluate(x_test, y_test)[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m/nix/store/wh2x3v6wrwijbl6g123a7awdyqz17hkh-python3-3.10.13-env/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/nix/store/wh2x3v6wrwijbl6g123a7awdyqz17hkh-python3-3.10.13-env/lib/python3.10/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/nix/store/wh2x3v6wrwijbl6g123a7awdyqz17hkh-python3-3.10.13-env/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/nix/store/wh2x3v6wrwijbl6g123a7awdyqz17hkh-python3-3.10.13-env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/nix/store/wh2x3v6wrwijbl6g123a7awdyqz17hkh-python3-3.10.13-env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/nix/store/wh2x3v6wrwijbl6g123a7awdyqz17hkh-python3-3.10.13-env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/nix/store/wh2x3v6wrwijbl6g123a7awdyqz17hkh-python3-3.10.13-env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/nix/store/wh2x3v6wrwijbl6g123a7awdyqz17hkh-python3-3.10.13-env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/nix/store/wh2x3v6wrwijbl6g123a7awdyqz17hkh-python3-3.10.13-env/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "print(\"shape of x_train:\", x_train.shape)\n",
    "print(\"shape of y_train:\", y_train.shape)\n",
    "\n",
    "nbClasses = np.unique(y_train).shape[0]\n",
    "inputDim = 784\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(int(inputDim  / 2) + nbClasses, input_dim=inputDim, activation='relu'))\n",
    "model.add(Dense(nbClasses, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train, nbClasses)\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test, nbClasses)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=150, batch_size=128, validation_split=0.2)\n",
    "DataFrame(history.history).plot()\n",
    "\n",
    "print(\"Test score:\", model.evaluate(x_test, y_test)[0])"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
