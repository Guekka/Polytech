{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rfp1U9PMeQU1"
   },
   "source": [
    "\n",
    "# TP CNN\n",
    "### Diane LINGRAND \n",
    "\n",
    "diane.lingrand@univ-cotedazur.fr   \n",
    "Polytech - SI4 - 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uo8ucmMpgEp9"
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "68uwyRRi4BMK"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import tensorflow\n",
    "print(tensorflow.__version__)\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Activation \n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZMrLWuFy9gn7"
   },
   "source": [
    "**The GPU**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TO0xCfDwz-zT"
   },
   "source": [
    "To enable GPU backend in Google colab for your notebook:\n",
    "\n",
    "1.   Runtime (top left corner) -> Change runtime type\n",
    "2.   Put GPU as \"Hardware accelerator\"\n",
    "3.   Save."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hHU7TK6FrHao"
   },
   "source": [
    "# Convolutional Neural Networks (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eP0L5uYbfAzC"
   },
   "source": [
    "Derived from the MLP, a convolutional neural network (CNN) is a type of artificial neural network that is specifically designed to process **pixel data**.  The layers of a CNN consist of an **input layer**, an **output layer** and **hidden layers** that can include **convolutional layers**, **pooling layers**, **fully connected layers** and **normalization layers**. It exists a lot of techniques to optimize CNN, like for example the dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bfCDrvt8qQPY"
   },
   "source": [
    "## Loading the dataset\n",
    "In this part, we will use photographies of animals from the kaggle dataset [animals-10](https://www.kaggle.com/alessiocorrado99/animals10). Please connect to their site before downloading the dataset from this [zip file](http://www.i3s.unice.fr/~lingrand/raw-img.zip). Decompress the zip file on your disk.\n",
    "\n",
    "If you are using google colab, there is no need to download the dataset because I have a copy on my drive. You just need add to your drive this shared folder: https://drive.google.com/drive/folders/15cB1Ky-7OTUqfcQDZZyzc5HArt0GA6Sm?usp=sharing\n",
    "You need to click on the link and click on \"Add shortcut to Drive\" and then select \"My Drive\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RM78thFqt-ZY"
   },
   "source": [
    "To feed the data to a CNN, we need to shape it as required by Keras. As input, a 2D convolutional layer needs a **4D tensor** with shape: **(batch, rows, cols, channels)**. Therefore, we need to precise the \"channels\" axis, which can be seen as the number of level of color of each input: 3 channels in our case. We will fix the dimension of images according to the VGG-16 network: (224, 224).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i_yPS5rYF1Sk"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, MaxPooling2D, Flatten\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import glob\n",
    "# when processing time is long, it's nice to see the progress bar\n",
    "#!pip install tqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IzHkKLqlZPn3"
   },
   "source": [
    "### loading train data\n",
    "\n",
    "Please read the code before running any of the cells!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gU_b3QQGZO58"
   },
   "outputs": [],
   "source": [
    "# WARNING: do not run this cell now. It is very time consuming. Run the next one and come back here if you have time later.\n",
    "#datasetRoot='/whereYouPutTheImages/'\n",
    "datasetRoot='/content/drive/My Drive/raw-img/'\n",
    "classes = ['mucca', 'elefante', 'gatto', 'cavallo', 'scoiattolo', 'ragno', 'pecora', 'farfalla', 'gallina', 'cane']\n",
    "nbClasses = len(classes)\n",
    "\n",
    "#training data\n",
    "\n",
    "rootTrain = datasetRoot+'train/'\n",
    "classLabel = 0\n",
    "reducedSizePerClass = 100 #in order to reduce the number of images per class\n",
    "totalImg = nbClasses * reducedSizePerClass\n",
    "xTrain = np.empty(shape=(totalImg,224,224,3))\n",
    "\n",
    "xTrain = np.empty(shape=(0,224,224,3))\n",
    "yTrain = []\n",
    "first = True\n",
    "for cl in tqdm(classes):\n",
    "    listImages = glob.glob(rootTrain+cl+'/*')\n",
    "    yTrain += [classLabel]*reducedSizePerClass#len(listImages) # note that here ...\n",
    "    for pathImg in tqdm(listImages[:reducedSizePerClass]): # and here, we have reduced the data to be loaded (only 100 per class)\n",
    "        img = image.load_img(pathImg, target_size=(224, 224))\n",
    "        im = image.img_to_array(img)\n",
    "        im = np.expand_dims(im, axis=0)\n",
    "        im = preprocess_input(im)\n",
    "        xTrain[i,:,:,:] = im\n",
    "        i+=1\n",
    "        #xTrain = np.vstack([xTrain, im])\n",
    "    classLabel += 1\n",
    "print(len(yTrain))\n",
    "print(xTrain.shape)\n",
    "yTrain = keras.utils.to_categorical(yTrain, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xkVd3v4N3LnB"
   },
   "outputs": [],
   "source": [
    "#datasetRoot='/home/lingrand/Ens/MachineLearning/animals/raw-img/'\n",
    "#datasetRoot='/whereYouPutTheImages/'\n",
    "datasetRoot='/content/drive/My Drive/DLS2020/raw-img/'\n",
    "classes = ['mucca', 'elefante']#, gatto', 'cavallo', 'scoiattolo', 'ragno', 'pecora', 'farfalla', 'gallina', 'cane']\n",
    "nbClasses = len(classes)\n",
    "\n",
    "#training data\n",
    "\n",
    "rootTrain = datasetRoot+'train/'\n",
    "classLabel = 0\n",
    "reducedSizePerClass = 200 #in order to reduce the number of images per class\n",
    "totalImg = nbClasses * reducedSizePerClass\n",
    "xTrain = np.empty(shape=(totalImg,224,224,3))\n",
    "yTrain = []\n",
    "first = True\n",
    "i= 0\n",
    "for cl in classes:\n",
    "    listImages = glob.glob(rootTrain+cl+'/*')\n",
    "    yTrain += [classLabel]*reducedSizePerClass #len(listImages) # note that here ...\n",
    "    for pathImg in tqdm(listImages[:reducedSizePerClass]): # and here, we have reduced the data to be loaded (only 1000 per class)\n",
    "        img = image.load_img(pathImg, target_size=(224,224))\n",
    "        im = image.img_to_array(img)\n",
    "        im = np.expand_dims(im, axis=0)\n",
    "        im = preprocess_input(im)\n",
    "        xTrain[i,:,:,:] = im\n",
    "        i += 1\n",
    "    classLabel += 1\n",
    "print(len(yTrain))\n",
    "print(xTrain.shape)\n",
    "yTrain = tensorflow.keras.utils.to_categorical(yTrain, nbClasses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56bq9oXanGUm"
   },
   "source": [
    "In order to speed-up the time spent on this part of the lab, you may have noticed that we reduced the number of classes and the number of images per class. You can change these few lines of code if you want to work on the whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "boNapUgGaEMj"
   },
   "source": [
    "### loading test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zwi5TBlKajtt"
   },
   "outputs": [],
   "source": [
    "#you will probably need to reduce the test dataset according to the train dataset rules\n",
    "rootTest = datasetRoot+'test/'\n",
    "classLabel = 0\n",
    "\n",
    "totalTestImg = 0\n",
    "for cl in classes:\n",
    "    totalTestImg += len(glob.glob(rootTest+cl+'/*'))\n",
    "\n",
    "xTest = np.empty(shape=(totalTestImg,224,224,3))\n",
    "yTest = []\n",
    "i = 0\n",
    "\n",
    "for cl in classes:\n",
    "    listImages = glob.glob(rootTest+cl+'/*')\n",
    "    yTest += [classLabel]*len(listImages)\n",
    "    for pathImg in listImages:\n",
    "        img = image.load_img(pathImg, target_size=(224, 224))\n",
    "        im = image.img_to_array(img)\n",
    "        im = np.expand_dims(im, axis=0)\n",
    "        im = preprocess_input(im)\n",
    "        xTest[i,:,:,:] = im \n",
    "    classLabel += 1\n",
    "print(len(yTest))\n",
    "print(xTest.shape)\n",
    "yTest = tensorflow.keras.utils.to_categorical(yTest, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Build your own CNN network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with the simplest CNN: 1 conv2D layer + 1 pooling + 1 dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbClasses = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16,(3,3),padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "model.add(Dense(nbClasses, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the dimension of all inputs and outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "hidden",
    "solution_first": true
   },
   "source": [
    "You will encounter errors telling you that some dimensions are incompatible. Why ? How to correct ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn and test this network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for you !\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for you !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "hidden",
    "solution_first": true
   },
   "source": [
    "How is the accuracy or F1-measure on the test dataset?\n",
    "\n",
    "Are you satisfied by the performances?\n",
    "\n",
    "Try to modify the architecture (add layers and neurons) and some of the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Using a pre-learned network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Og1KZntwavZT"
   },
   "source": [
    "## loading VGG-16 description part and adding layers to build our own classification network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ofrQr-x_a-Bi"
   },
   "outputs": [],
   "source": [
    "VGGmodel = VGG16(weights='imagenet', include_top=False)\n",
    "features = VGGmodel.predict(xTrain)\n",
    "print(features.shape)\n",
    "\n",
    "# we will add layers to this feature extraction part of VGG network\n",
    "m = VGGmodel.output\n",
    "# we start with a global average pooling\n",
    "m = GlobalAveragePooling2D()(m)\n",
    "# and add a fully-connected layer\n",
    "m = Dense(1024, activation='relu')(m)\n",
    "# finally, the softmax layer for predictions (we have nbClasses classes)\n",
    "predictions = Dense(nbClasses, activation='softmax')(m)\n",
    "\n",
    "# global network\n",
    "model = Model(inputs=VGGmodel.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6POPQoXcbPuc",
    "solution": "hidden",
    "solution_first": true
   },
   "source": [
    "Can you display the architecture of this entire network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PrLUhA2-b8Fv"
   },
   "outputs": [],
   "source": [
    "# training\n",
    "ourCallback = tensorflow.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=20, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    " \n",
    "# training part I: training only the classification part (the end)\n",
    "for layer in VGGmodel.layers:\n",
    "    layer.trainable = False\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(xTrain, yTrain, epochs=2000, batch_size=128, validation_split=0.2, callbacks=[ourCallback],verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4hgDguiNcNXZ"
   },
   "source": [
    "# fine-tune the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L9jmknEpcT1_"
   },
   "source": [
    "Fine-tune the entire network if you have enough computing ressouces, otherwise, carefully choose the layers you want to fine-tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cRr97-2yc6kZ"
   },
   "outputs": [],
   "source": [
    "for i, layer in enumerate(VGGmodel.layers):\n",
    "   print(i, layer.name)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v4eCse6wku5Q"
   },
   "source": [
    "In this example, we will fine-tune the last convolution block starting at layer number 15 (block5_conv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C17ts6kllGUr"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "for layer in model.layers[:15]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[15:]:\n",
    "   layer.trainable = True\n",
    "#need to recompile the network\n",
    "model.compile(optimizer=RMSprop(learning_rate=0.0001), loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "#and train again ...\n",
    "model.fit(xTrain, yTrain, epochs=2000, batch_size=128, validation_split=0.2, callbacks=[ourCallback],verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6LrhxQiBmTZj",
    "solution": "hidden",
    "solution_first": true
   },
   "source": [
    "You already know how to evaluate the performances on the test dataset and display the confusion matrix. You can also modify the code that loads the test dataset in order to reduce it's size. Let's do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RHGxb-PxmiYd"
   },
   "outputs": [],
   "source": [
    "#enter here your code for evaluation of performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "unzKoPOsgNW3",
    "solution": "hidden",
    "solution_first": true
   },
   "source": [
    "You are now free to experiments changes in the network:\n",
    "* add a dense layer\n",
    "* modify the number of neurons in dense layer(s)\n",
    "* change the global average polling\n",
    "* add classes and data\n",
    "\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ImageClassificationUsingDeepLearning.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
