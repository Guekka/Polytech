{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Google Speech Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 14:02:31.847635: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-05 14:02:31.908015: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-05 14:02:31.908073: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-05 14:02:31.908130: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-05 14:02:31.918973: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-05 14:02:31.919720: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-05 14:02:33.111279: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import wave\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Conv1D, AvgPool1D, MaxPool1D, ZeroPadding1D, BatchNormalization, Flatten, Dense, Activation\n",
    "from keras.activations import softmax\n",
    "from keras.utils import get_file\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download, cache and extract Google Speech Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = Path('datasets')\n",
    "if not (dataset_dir/'testing_list.txt').exists(): # Assume dataset already downloaded/extracted if testing list is present\n",
    "    get_file(None, \"http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz\",\n",
    "                    extract=True,\n",
    "                    file_hash=\"6b74f3901214cb2c2934e98196829835\",\n",
    "                    cache_dir='.',\n",
    "                    cache_subdir=dataset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw spoken digits data from Google Speech Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes to handle, ordered by label\n",
    "CLASSES = ['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']\n",
    "\n",
    "with (dataset_dir/'testing_list.txt').open() as f:\n",
    "    testing_list = f.read().splitlines()\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for recording in dataset_dir.glob(f'**/*.wav'):\n",
    "    if not recording.parent.name in CLASSES: # Ignore unused classes\n",
    "        continue\n",
    "    label = CLASSES.index(recording.parent.name) # Assign class number\n",
    "    \n",
    "    with wave.open(str(recording)) as f: # Read wave file\n",
    "        data = np.frombuffer(f.readframes(f.getnframes()), dtype=np.int16).copy() # As 16-bit signed integer\n",
    "        \n",
    "    data = data.astype(np.float32) # Convert to 32-bit floating-point\n",
    "    data.resize((16000, 1)) # Resize to 1s (16kHz) with zero-padding, 1 channel\n",
    "\n",
    "    if str(recording.relative_to(dataset_dir)) in testing_list: # Assign to test set if file in test list\n",
    "        x_test.append(data)\n",
    "        y_test.append(label)\n",
    "    else:\n",
    "        x_train.append(data)\n",
    "        y_train.append(label)\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = to_categorical(np.array(y_train))\n",
    "x_test = np.array(x_test)\n",
    "y_test = to_categorical(np.array(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for inference with fixed-point Q7.9 samples by scaling input data accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIXED_POINT = 9\n",
    "x_train /= 2**FIXED_POINT\n",
    "x_test  /= 2**FIXED_POINT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export small dataset (250 random vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "perms = np.random.permutation(len(y_test))[0:250]\n",
    "x_test_250 = x_test[perms]\n",
    "y_test_250 = y_test[perms]\n",
    "np.savetxt('x_test_gsc_250.csv', x_test_250.reshape((x_test_250.shape[0], -1)), delimiter=',', fmt='%s')\n",
    "np.savetxt('y_test_gsc_250.csv', y_test_250, delimiter=',', fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build model M5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " max_pooling1d_4 (MaxPoolin  (None, 800, 1)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 761, 8)            328       \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPoolin  (None, 190, 8)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 188, 16)           400       \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPoolin  (None, 47, 16)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 45, 32)            1568      \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPoolin  (None, 11, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " average_pooling1d_1 (Avera  (None, 1, 32)             0         \n",
      " gePooling1D)                                                    \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2626 (10.26 KB)\n",
      "Trainable params: 2626 (10.26 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(16000, 1)))\n",
    "model.add(MaxPool1D(pool_size=20, padding='valid'))\n",
    "model.add(Conv1D(filters=8, kernel_size=40, activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=4, padding='valid'))\n",
    "model.add(Conv1D(filters=16, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=4, padding='valid'))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=4, padding='valid'))\n",
    "model.add(AvgPool1D(pool_size=8))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=10))\n",
    "model.add(Activation('softmax'))  # SoftMax activation needs to be separate from Dense to remove it later on# EXPLORE Learning Rate\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=10e-3)\n",
    "model.summary()\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "91/91 [==============================] - 6s 49ms/step - loss: 2.2322 - categorical_accuracy: 0.1694 - val_loss: 2.0756 - val_categorical_accuracy: 0.2289\n",
      "Epoch 2/50\n",
      "91/91 [==============================] - 4s 44ms/step - loss: 1.8950 - categorical_accuracy: 0.3269 - val_loss: 1.7658 - val_categorical_accuracy: 0.3876\n",
      "Epoch 3/50\n",
      "91/91 [==============================] - 4s 45ms/step - loss: 1.7285 - categorical_accuracy: 0.4127 - val_loss: 1.6641 - val_categorical_accuracy: 0.4290\n",
      "Epoch 4/50\n",
      "91/91 [==============================] - 4s 44ms/step - loss: 1.6415 - categorical_accuracy: 0.4515 - val_loss: 1.6520 - val_categorical_accuracy: 0.4390\n",
      "Epoch 5/50\n",
      "91/91 [==============================] - 4s 45ms/step - loss: 1.5788 - categorical_accuracy: 0.4752 - val_loss: 1.5191 - val_categorical_accuracy: 0.4843\n",
      "Epoch 6/50\n",
      "91/91 [==============================] - 4s 45ms/step - loss: 1.5287 - categorical_accuracy: 0.4933 - val_loss: 1.5050 - val_categorical_accuracy: 0.4918\n",
      "Epoch 7/50\n",
      "91/91 [==============================] - 4s 46ms/step - loss: 1.5016 - categorical_accuracy: 0.5058 - val_loss: 1.4737 - val_categorical_accuracy: 0.5052\n",
      "Epoch 8/50\n",
      "91/91 [==============================] - 4s 45ms/step - loss: 1.4597 - categorical_accuracy: 0.5158 - val_loss: 1.4451 - val_categorical_accuracy: 0.5177\n",
      "Epoch 9/50\n",
      "91/91 [==============================] - 4s 48ms/step - loss: 1.4308 - categorical_accuracy: 0.5287 - val_loss: 1.3919 - val_categorical_accuracy: 0.5386\n",
      "Epoch 10/50\n",
      "91/91 [==============================] - 4s 46ms/step - loss: 1.4129 - categorical_accuracy: 0.5325 - val_loss: 1.4672 - val_categorical_accuracy: 0.5181\n",
      "Epoch 11/50\n",
      "91/91 [==============================] - 4s 44ms/step - loss: 1.3912 - categorical_accuracy: 0.5363 - val_loss: 1.3943 - val_categorical_accuracy: 0.5252\n",
      "Epoch 12/50\n",
      "91/91 [==============================] - 4s 45ms/step - loss: 1.3471 - categorical_accuracy: 0.5525 - val_loss: 1.3517 - val_categorical_accuracy: 0.5425\n",
      "Epoch 13/50\n",
      "91/91 [==============================] - 4s 46ms/step - loss: 1.3261 - categorical_accuracy: 0.5627 - val_loss: 1.3216 - val_categorical_accuracy: 0.5427\n",
      "Epoch 14/50\n",
      "91/91 [==============================] - 4s 44ms/step - loss: 1.3057 - categorical_accuracy: 0.5672 - val_loss: 1.2979 - val_categorical_accuracy: 0.5644\n",
      "Epoch 15/50\n",
      "91/91 [==============================] - 4s 44ms/step - loss: 1.2903 - categorical_accuracy: 0.5715 - val_loss: 1.3062 - val_categorical_accuracy: 0.5627\n",
      "Epoch 16/50\n",
      "91/91 [==============================] - 4s 45ms/step - loss: 1.2772 - categorical_accuracy: 0.5752 - val_loss: 1.2845 - val_categorical_accuracy: 0.5673\n",
      "Epoch 17/50\n",
      "91/91 [==============================] - 4s 44ms/step - loss: 1.2635 - categorical_accuracy: 0.5812 - val_loss: 1.2692 - val_categorical_accuracy: 0.5817\n",
      "Epoch 18/50\n",
      "91/91 [==============================] - 4s 44ms/step - loss: 1.2442 - categorical_accuracy: 0.5835 - val_loss: 1.2756 - val_categorical_accuracy: 0.5751\n",
      "Epoch 19/50\n",
      "91/91 [==============================] - 4s 43ms/step - loss: 1.2378 - categorical_accuracy: 0.5875 - val_loss: 1.2624 - val_categorical_accuracy: 0.5797\n",
      "Epoch 20/50\n",
      "91/91 [==============================] - 4s 43ms/step - loss: 1.2431 - categorical_accuracy: 0.5862 - val_loss: 1.2495 - val_categorical_accuracy: 0.5878\n",
      "Epoch 21/50\n",
      "91/91 [==============================] - 4s 43ms/step - loss: 1.2220 - categorical_accuracy: 0.5896 - val_loss: 1.2849 - val_categorical_accuracy: 0.5722\n",
      "Epoch 22/50\n",
      "91/91 [==============================] - 4s 44ms/step - loss: 1.2105 - categorical_accuracy: 0.5946 - val_loss: 1.2669 - val_categorical_accuracy: 0.5732\n",
      "Epoch 23/50\n",
      "91/91 [==============================] - 4s 44ms/step - loss: 1.2112 - categorical_accuracy: 0.5927 - val_loss: 1.2895 - val_categorical_accuracy: 0.5715\n",
      "Epoch 24/50\n",
      "91/91 [==============================] - 4s 44ms/step - loss: 1.1965 - categorical_accuracy: 0.5971 - val_loss: 1.2358 - val_categorical_accuracy: 0.5768\n",
      "Epoch 25/50\n",
      "91/91 [==============================] - 4s 45ms/step - loss: 1.1895 - categorical_accuracy: 0.5998 - val_loss: 1.2118 - val_categorical_accuracy: 0.5917\n",
      "Epoch 26/50\n",
      "91/91 [==============================] - 4s 44ms/step - loss: 1.1999 - categorical_accuracy: 0.5955 - val_loss: 1.2206 - val_categorical_accuracy: 0.5810\n",
      "Epoch 27/50\n",
      "91/91 [==============================] - 4s 44ms/step - loss: 1.1709 - categorical_accuracy: 0.6076 - val_loss: 1.1935 - val_categorical_accuracy: 0.5944\n",
      "Epoch 28/50\n",
      "91/91 [==============================] - 4s 43ms/step - loss: 1.1748 - categorical_accuracy: 0.6040 - val_loss: 1.2355 - val_categorical_accuracy: 0.5807\n",
      "Epoch 29/50\n",
      "91/91 [==============================] - 4s 45ms/step - loss: 1.1680 - categorical_accuracy: 0.6073 - val_loss: 1.2109 - val_categorical_accuracy: 0.5841\n",
      "Epoch 30/50\n",
      "91/91 [==============================] - 4s 45ms/step - loss: 1.1668 - categorical_accuracy: 0.6031 - val_loss: 1.2184 - val_categorical_accuracy: 0.5810\n",
      "Epoch 31/50\n",
      "91/91 [==============================] - 4s 45ms/step - loss: 1.1638 - categorical_accuracy: 0.6047 - val_loss: 1.2244 - val_categorical_accuracy: 0.5717\n",
      "Epoch 32/50\n",
      "91/91 [==============================] - 4s 44ms/step - loss: 1.1548 - categorical_accuracy: 0.6104 - val_loss: 1.2386 - val_categorical_accuracy: 0.5861\n",
      "Epoch 33/50\n",
      "91/91 [==============================] - 4s 46ms/step - loss: 1.1491 - categorical_accuracy: 0.6112 - val_loss: 1.2100 - val_categorical_accuracy: 0.5922\n",
      "Epoch 34/50\n",
      "91/91 [==============================] - 4s 45ms/step - loss: 1.1486 - categorical_accuracy: 0.6128 - val_loss: 1.1958 - val_categorical_accuracy: 0.5907\n",
      "Epoch 35/50\n",
      "91/91 [==============================] - 4s 45ms/step - loss: 1.1496 - categorical_accuracy: 0.6118 - val_loss: 1.1893 - val_categorical_accuracy: 0.6051\n",
      "Epoch 36/50\n",
      "91/91 [==============================] - 4s 44ms/step - loss: 1.1346 - categorical_accuracy: 0.6152 - val_loss: 1.2059 - val_categorical_accuracy: 0.5939\n",
      "Epoch 37/50\n",
      "91/91 [==============================] - 4s 44ms/step - loss: 1.1443 - categorical_accuracy: 0.6105 - val_loss: 1.2455 - val_categorical_accuracy: 0.5839\n",
      "Epoch 38/50\n",
      "91/91 [==============================] - 4s 45ms/step - loss: 1.1436 - categorical_accuracy: 0.6134 - val_loss: 1.1856 - val_categorical_accuracy: 0.6000\n",
      "Epoch 39/50\n",
      "91/91 [==============================] - 4s 46ms/step - loss: 1.1283 - categorical_accuracy: 0.6194 - val_loss: 1.1890 - val_categorical_accuracy: 0.5948\n",
      "Epoch 40/50\n",
      "91/91 [==============================] - 4s 45ms/step - loss: 1.1278 - categorical_accuracy: 0.6197 - val_loss: 1.1831 - val_categorical_accuracy: 0.5919\n",
      "Epoch 41/50\n",
      "91/91 [==============================] - 4s 44ms/step - loss: 1.1253 - categorical_accuracy: 0.6172 - val_loss: 1.1814 - val_categorical_accuracy: 0.5997\n",
      "Epoch 42/50\n",
      "91/91 [==============================] - 4s 47ms/step - loss: 1.1231 - categorical_accuracy: 0.6191 - val_loss: 1.1755 - val_categorical_accuracy: 0.5973\n",
      "Epoch 43/50\n",
      "91/91 [==============================] - 4s 46ms/step - loss: 1.1102 - categorical_accuracy: 0.6257 - val_loss: 1.2116 - val_categorical_accuracy: 0.5892\n",
      "Epoch 44/50\n",
      "91/91 [==============================] - 4s 45ms/step - loss: 1.1157 - categorical_accuracy: 0.6236 - val_loss: 1.1944 - val_categorical_accuracy: 0.5909\n",
      "Epoch 45/50\n",
      "91/91 [==============================] - 4s 45ms/step - loss: 1.1118 - categorical_accuracy: 0.6231 - val_loss: 1.2095 - val_categorical_accuracy: 0.5944\n",
      "Epoch 46/50\n",
      "91/91 [==============================] - 4s 45ms/step - loss: 1.1085 - categorical_accuracy: 0.6208 - val_loss: 1.2030 - val_categorical_accuracy: 0.5917\n",
      "Epoch 47/50\n",
      "91/91 [==============================] - 4s 44ms/step - loss: 1.1020 - categorical_accuracy: 0.6251 - val_loss: 1.1946 - val_categorical_accuracy: 0.6000\n",
      "Epoch 48/50\n",
      "91/91 [==============================] - 4s 48ms/step - loss: 1.1045 - categorical_accuracy: 0.6248 - val_loss: 1.1803 - val_categorical_accuracy: 0.5956\n",
      "Epoch 49/50\n",
      "91/91 [==============================] - 4s 46ms/step - loss: 1.1090 - categorical_accuracy: 0.6251 - val_loss: 1.1990 - val_categorical_accuracy: 0.5929\n",
      "Epoch 50/50\n",
      "91/91 [==============================] - 4s 48ms/step - loss: 1.0987 - categorical_accuracy: 0.6268 - val_loss: 1.1991 - val_categorical_accuracy: 0.5931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f0399633d90>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=50, batch_size=384, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 - 1s - loss: 1.1991 - categorical_accuracy: 0.5931 - 785ms/epoch - 6ms/step\n",
      "129/129 [==============================] - 1s 6ms/step\n",
      "tf.Tensor(\n",
      "[[207  37   9  62  29   7  15  18   7  27]\n",
      " [ 26 246   2  25   4   9   4   4  28  51]\n",
      " [  1   4 276  53  21   2  20  10  36   1]\n",
      " [ 20  17  53 193  37  13  24  19  27   2]\n",
      " [ 15  12  14  62 160  64  30  26  13   4]\n",
      " [  7   7  12  24  55 257  21  24  34   4]\n",
      " [  1   1   7  15  13   7 328  15   7   0]\n",
      " [  4   8  11  25  12  14  53 277   2   0]\n",
      " [  4  22  13  41  16  24  26   5 250   7]\n",
      " [ 24  92   2  22   5   6   6   0   9 242]], shape=(10, 10), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)\n",
    "pred_test = model.predict(x_test)\n",
    "print(tf.math.confusion_matrix(y_test.argmax(axis=1), pred_test.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate model on small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 0s - loss: 1.3492 - categorical_accuracy: 0.5360 - 86ms/epoch - 11ms/step\n",
      "8/8 [==============================] - 0s 7ms/step\n",
      "tf.Tensor(\n",
      "[[ 7  5  2  5  0  1  1  1  1  1]\n",
      " [ 2 13  0  0  0  1  1  0  6  4]\n",
      " [ 0  1 20  5  2  0  0  0  5  0]\n",
      " [ 1  2  4 12  2  1  0  0  2  0]\n",
      " [ 1  0  0  4 12  5  0  2  1  0]\n",
      " [ 0  2  1  1  2 17  1  0  1  0]\n",
      " [ 0  0  0  0  1  0 18  2  0  0]\n",
      " [ 1  0  1  2  3  2  2 15  0  0]\n",
      " [ 1  2  0  2  2  2  1  0 12  1]\n",
      " [ 2  9  0  0  1  1  0  0  1  8]], shape=(10, 10), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test_250, y_test_250, verbose=2)\n",
    "pred_test_250 = model.predict(x_test_250)\n",
    "print(tf.math.confusion_matrix(y_test_250.argmax(axis=1), pred_test_250.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('lab_gsc.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove SoftMax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(model.layers[-1], Activation) and model.layers[-1].activation == softmax:\n",
    "    model = tf.keras.Model(model.input, model.layers[-2].output, name=model.name)\n",
    "else:\n",
    "    print('Error: last layer is not SoftMax Activation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Qualia-CodeGen for C inference code generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qualia_codegen_core in /opt/conda/lib/python3.11/site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from qualia_codegen_core) (1.24.4)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from qualia_codegen_core) (3.1.2)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.11/site-packages (from qualia_codegen_core) (4.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->qualia_codegen_core) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install qualia_codegen_core\n",
    "import qualia_codegen_core\n",
    "from qualia_codegen_core.graph.KerasModelGraph import KerasModelGraph\n",
    "from qualia_codegen_core.graph.Quantization import Quantization\n",
    "from qualia_codegen_core.graph.RoundMode import RoundMode\n",
    "\n",
    "from importlib.resources import files\n",
    "main_path = str((files('qualia_codegen_core.examples')/'Linux'/'main.cpp').resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Keras Model to Qualia-CodeGen's internal representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Inputs                                           | Layer                                            | Outputs                                          | Input shape                                      | Output shape                                    \n",
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "                                                 | input_4                                          | max_pooling1d_4                                  | (1, 16000, 1)                                    | ((1, 16000, 1),)                                \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "input_4                                          | max_pooling1d_4                                  | conv1d_3                                         | (1, 16000, 1)                                    | ((1, 800, 1),)                                  \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_4                                  | conv1d_3                                         | max_pooling1d_5                                  | (1, 800, 1)                                      | ((1, 761, 8),)                                  \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "conv1d_3                                         | max_pooling1d_5                                  | conv1d_4                                         | (1, 761, 8)                                      | ((1, 190, 8),)                                  \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_5                                  | conv1d_4                                         | max_pooling1d_6                                  | (1, 190, 8)                                      | ((1, 188, 16),)                                 \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "conv1d_4                                         | max_pooling1d_6                                  | conv1d_5                                         | (1, 188, 16)                                     | ((1, 47, 16),)                                  \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_6                                  | conv1d_5                                         | max_pooling1d_7                                  | (1, 47, 16)                                      | ((1, 45, 32),)                                  \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "conv1d_5                                         | max_pooling1d_7                                  | average_pooling1d_1                              | (1, 45, 32)                                      | ((1, 11, 32),)                                  \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_7                                  | average_pooling1d_1                              | flatten_3                                        | (1, 11, 32)                                      | ((1, 1, 32),)                                   \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "average_pooling1d_1                              | flatten_3                                        | dense_3                                          | (1, 1, 32)                                       | ((1, 32),)                                      \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "flatten_3                                        | dense_3                                          |                                                  | (1, 32)                                          | ((1, 10),)                                      \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelgraph = KerasModelGraph(model).convert()\n",
    "print(modelgraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate C code for the trained model with 32-bit floating-point representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graphviz not available\n"
     ]
    }
   ],
   "source": [
    "float_modelgraph = copy.deepcopy(modelgraph)\n",
    "\n",
    "# layer quantization annotations for float32\n",
    "for node in float_modelgraph.nodes:\n",
    "    # No scale factor if not fixed-point quantization on integers\n",
    "    node.q = Quantization(\n",
    "            number_type=float,\n",
    "            width=32,\n",
    "            long_width=32,\n",
    "            weights_scale_factor=0,\n",
    "            output_scale_factor=0,\n",
    "            weights_round_mode=RoundMode.NONE,\n",
    "            output_round_mode=RoundMode.NONE,\n",
    "            )\n",
    "\n",
    "float_res = qualia_codegen_core.Converter(output_path=Path('gsc_output_floating')).convert_model(float_modelgraph)\n",
    "\n",
    "with open('gsc_model_floating.h', 'w') as f:\n",
    "    f.write(float_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the 32-bit floating-point C code for x86 and evaluate on small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In file included from \u001b[01m\u001b[Kgsc_output_floating/model.c:15\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[Kgsc_output_floating/include/number.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kfloat scale_number_t_float(float, int, round_mode_t)\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[Kgsc_output_floating/include/number.h:143:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused parameter ‘\u001b[01m\u001b[Kscale_factor\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-parameter\u0007-Wunused-parameter\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  143 |   float number, \u001b[01;35m\u001b[Kint scale_factor\u001b[m\u001b[K, round_mode_t round_mode) {\n",
      "      |                 \u001b[01;35m\u001b[K~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kgsc_output_floating/include/number.h:143:48:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused parameter ‘\u001b[01m\u001b[Kround_mode\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-parameter\u0007-Wunused-parameter\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  143 |   float number, int scale_factor, \u001b[01;35m\u001b[Kround_mode_t round_mode\u001b[m\u001b[K) {\n",
      "      |                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~^~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kgsc_output_floating/include/number.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kfloat scale_and_clamp_to_number_t_float(float, int, round_mode_t)\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[Kgsc_output_floating/include/number.h:151:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused parameter ‘\u001b[01m\u001b[Kscale_factor\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-parameter\u0007-Wunused-parameter\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  151 |   float number, \u001b[01;35m\u001b[Kint scale_factor\u001b[m\u001b[K, round_mode_t round_mode) {\n",
      "      |                 \u001b[01;35m\u001b[K~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kgsc_output_floating/include/number.h:151:48:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused parameter ‘\u001b[01m\u001b[Kround_mode\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-parameter\u0007-Wunused-parameter\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  151 |   float number, int scale_factor, \u001b[01;35m\u001b[Kround_mode_t round_mode\u001b[m\u001b[K) {\n",
      "      |                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~^~~~~~~~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[Kgsc_output_floating/include/model.h:19\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.11/site-packages/qualia_codegen_core/examples/Linux/main.cpp:12\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[Kgsc_output_floating/include/number.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kfloat scale_number_t_float(float, int, round_mode_t)\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[Kgsc_output_floating/include/number.h:143:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused parameter ‘\u001b[01m\u001b[Kscale_factor\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-parameter\u0007-Wunused-parameter\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  143 |   float number, \u001b[01;35m\u001b[Kint scale_factor\u001b[m\u001b[K, round_mode_t round_mode) {\n",
      "      |                 \u001b[01;35m\u001b[K~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kgsc_output_floating/include/number.h:143:48:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused parameter ‘\u001b[01m\u001b[Kround_mode\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-parameter\u0007-Wunused-parameter\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  143 |   float number, int scale_factor, \u001b[01;35m\u001b[Kround_mode_t round_mode\u001b[m\u001b[K) {\n",
      "      |                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~^~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kgsc_output_floating/include/number.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kfloat scale_and_clamp_to_number_t_float(float, int, round_mode_t)\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[Kgsc_output_floating/include/number.h:151:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused parameter ‘\u001b[01m\u001b[Kscale_factor\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-parameter\u0007-Wunused-parameter\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  151 |   float number, \u001b[01;35m\u001b[Kint scale_factor\u001b[m\u001b[K, round_mode_t round_mode) {\n",
      "      |                 \u001b[01;35m\u001b[K~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kgsc_output_floating/include/number.h:151:48:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused parameter ‘\u001b[01m\u001b[Kround_mode\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-parameter\u0007-Wunused-parameter\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  151 |   float number, int scale_factor, \u001b[01;35m\u001b[Kround_mode_t round_mode\u001b[m\u001b[K) {\n",
      "      |                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~^~~~~~~~~~\u001b[m\u001b[K\n",
      "Testing accuracy: 0.536\n"
     ]
    }
   ],
   "source": [
    "!g++ -std=c++17 -Wall -Wextra -pedantic -Ofast -o gsc_floating -include gsc_output_floating/include/defines.h -Igsc_output_floating/include gsc_output_floating/model.c {main_path}\n",
    "!./gsc_floating x_test_gsc_250.csv y_test_gsc_250.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate C code for the trained model with 16-bit fixed-point representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graphviz not available\n"
     ]
    }
   ],
   "source": [
    "fixed_modelgraph = copy.deepcopy(modelgraph)\n",
    "\n",
    "# layer quantization annotations for int16 Q9.7\n",
    "for node in fixed_modelgraph.nodes:\n",
    "    node.q = Quantization(\n",
    "            number_type=int,\n",
    "            width=16,\n",
    "            long_width=32,\n",
    "            weights_scale_factor=7,\n",
    "            output_scale_factor=7,\n",
    "            weights_round_mode=RoundMode.FLOOR,\n",
    "            output_round_mode=RoundMode.FLOOR,\n",
    "            )\n",
    "\n",
    "fixed_res = qualia_codegen_core.Converter(output_path=Path('gsc_output_fixed')).convert_model(fixed_modelgraph)\n",
    "\n",
    "with open('gsc_model_fixed.h', 'w') as f:\n",
    "    f.write(fixed_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compile the 16-bit fixed-point C code for x86 and evaluate on small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: ./gsc_fixed: cannot execute binary file: Exec format error\n"
     ]
    }
   ],
   "source": [
    "!g++ -std=c++17 -Wall -Wextra -pedantic -Ofast -o gsc_fixed -include gsc_output_fixed/include/defines.h -Igsc_output_fixed/include gsc_model_fixed.h\n",
    "!./gsc_fixed x_test_gsc_250.csv y_test_gsc_250.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
